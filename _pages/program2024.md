---
title: "DeepLife - Program"
layout: textlay
sitemap: false
permalink: /program2024
---

## Program

This course will be organized in 4 blocks over 14 weeks (start: week of 26.02.2024)

1. Basic concepts in deep learning – 4 weeks
2. DL in single-cell genomics – 3 weeks
3. DL in protein bioinformatics - 4 weeks
4. DL in image analysis – 3 weeks
<br>

The course format will comprise a weekly **90-minute online lecture** and a **weekly hybrid (in-person/online) practical Python session**. Lectures will be given by [teachers]({{ site.url }}{{ site.baseurl }}/team) from all participating universities. Lectures and practical exercises on all three application areas will be centered around one **recent publication** illustrating a specific application and method.
<br>

The course will end with a 2-day workshop and **hackathon meeting** in Heidelberg in June 2024 during which students will be able to implement a short project and listen to scientific lectures.


## Prerequisites {#Prerequisites}

Students attending this course are expected to have some basic statistics knowledge and machine-learning fundamentals. 
Recommended books are among others:

1. [Deep Learning book](https://www.deeplearningbook.org/) by Goodfellow, Bengio, Courville
2. [The Elements of Statistical Learning](https://hastie.su.domains/Papers/ESLII.pdf) by Hastie, Tibshirani, Friedman
3. [An Introduction to Statistical Learning](https://www.statlearning.com/) by Hastie, Tibshirani, Friedman (a simpler version of the previous book)
4. [Machine learning with PyTorch and scikit-learn](https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312) by Raschka, Liu, Mirjalili (a great introduction into the technical aspects of DL in pyTorch).

As the practical sessions will be mostly based on Python and pyTorch, some basic knowledge in python is required (see reference [4] for a good overview of pyTorch for example).

Specifically, we expect that the following theoretical concepts are familiar:

#### basic statistics 

* accuracy
* sensitivity/specificity
* area under the curve (AUC)
* probability distributions
* random variable
* expectation of a random variable

#### machine-learning

* overfitting vs. underfitting
* cross-validation
* usage of training, validation and testing datasets
* classification vs. regression (supervised vs. unsupervised)
* binary vs. multi-class classification
* standard ML algorithms such as Random Forest

#### mathematical foundations

* matrix algebra


## Schedule of lectures

[Zoom link to weekly online lectures](https://eu02web.zoom-x.de/j/69290726331)

{% include program_table2024.html %}

<br>
<br>

